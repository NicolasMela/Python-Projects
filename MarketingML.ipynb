{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Customer Bank Term Deposit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using Bank Marketing data from UC Irvine's Machine Learning Repository. This data is related to the marketing campaigns of a Portugese banking institution. These marketing campaigns were based on calls to clients to determine if they would be subscribing to a bank term deposit. \n",
    "\n",
    "The structure of this project is as follows:\n",
    "- First import and view the data\n",
    "- Focus on cleaning the dataset from it's missing values\n",
    "- Preprocessing the data for our machine learning model\n",
    "- Finally build the ML model to predict if a client would subscribe to a term deposit or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data From UC Irvine Machine Learning Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "  \n",
    "# fetch dataset \n",
    "bank_marketing = fetch_ucirepo(id=222) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = bank_marketing.data.features \n",
    "y = bank_marketing.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(bank_marketing.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(bank_marketing.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View summary statistics\n",
    "print(X.describe())\n",
    "print(y.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View df info\n",
    "print(X.info)\n",
    "print(y.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View dataframe data types\n",
    "print(X.dtypes)\n",
    "print(y.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the categorical features to numeric ones using get_dummies() method from pandas\n",
    "X_dummies = pd.get_dummies(X)\n",
    "\n",
    "pd.set_option('display.max_column', None)\n",
    "\n",
    "X_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boolean values (True/False) to binary (0/1)\n",
    "X_dummies = X_dummies.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummies.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing y df from \"yes/no\" to True/False\n",
    "mapping = {'yes' : True, 'no': False}\n",
    "\n",
    "# Apply mapping to column\n",
    "y['y'] = y['y'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boolean values in output variable to binary 0/1 values\n",
    "y_dummies = y.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Statistical Correlation between Predictor Variables (X) and Target Variable (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at correlation with heatmap\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.concat([X_dummies, y_dummies], axis = 1)\n",
    "\n",
    "sns.heatmap(df.corr(), cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()\n",
    "\n",
    "corr_target = corr_matrix.iloc[:-1, -1]\n",
    "\n",
    "sorted_corr = corr_target.abs().sort_values(ascending=False)\n",
    "\n",
    "print(sorted_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets (80% for training, 20% for testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dummies, y_dummies, test_size=0.2, random_state=1) \n",
    "\n",
    "# 'test_size' determines the proportion of the dataset used for the training and testing data\n",
    "# 'random_state' sets the seed for reproducability "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest Classifier instance\n",
    "model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Train the classifier on training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model to predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracey\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what we see in the accuracy score, our model is approximately 90% accurate in it's predictions. However, the classification report shows our model is generally better at predicting if a customer will not subscribe to a bank term deposit then if they will"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set hyperparameters\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create GridSearchCV instance with the parameter grid\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check best parameters for the model\n",
    "\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest Classifier model with the best hyperparameters\n",
    "model2 = RandomForestClassifier(random_state=1, n_estimators=150, max_depth=30, min_samples_split=5)\n",
    "\n",
    "# Train the classifier on the entire training data\n",
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data once again\n",
    "y_pred2 = model2.predict(X_test)\n",
    "\n",
    "accuracy2 = accuracy_score(y_test, y_pred2)\n",
    "print(f'Accuracy: {accuracy2}')\n",
    "\n",
    "report2 = classification_report(y_test, y_pred2)\n",
    "print(report2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case of the new model, the accuracy is identical to the accuracy of the initial model, indicating that the hyperparameters tuned did not have a significant impact on the mode;'s performance for this specific dataset. \n",
    "Next possible steps to take this project even further would be to try different model algorithms, such as Gradient Boossitng, Support Vector Machines, or Neural Networks. You could also revisit hyperparameter tuning, gather \n",
    "more data, or revisit your feature selection. This is why domain knowledge in data analysis is so important, since you can guide your feature selection based on your industry knowledge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisiting Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the missing values in the initial dataset\n",
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this new selection of features, I decide to now fill all missing values with the most common values that are in those columns. However, I want to note the 'poutcome' column having almost all null values. I believe having previous data in knowing what the client answered in previous phone calls is important, but since there is practically barely any data in this case, I decide to just drop the column alltogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X.drop('poutcome', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now going to replace null values with most frequent value\n",
    "\n",
    "columns_replace = ['job', 'education', 'contact']\n",
    "\n",
    "for col in columns_replace:\n",
    "    most_frequent_value = X2[col].mode()[0]\n",
    "    X2[col].fillna(most_frequent_value, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummies2 = pd.get_dummies(X2)\n",
    "\n",
    "pd.set_option('display.max_column', None)\n",
    "\n",
    "X_dummies2.head()\n",
    "\n",
    "# Convert boolean values (True/False) to binary (0/1)\n",
    "X_dummies2 = X_dummies2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model with Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dummies2, y_dummies, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest Classifier instance\n",
    "model3 = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Train the classifier on training data\n",
    "model3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data once again\n",
    "y_pred3 = model3.predict(X_test)\n",
    "\n",
    "accuracy3 = accuracy_score(y_test, y_pred3)\n",
    "print(f'Accuracy: {accuracy3}')\n",
    "\n",
    "report3 = classification_report(y_test, y_pred3)\n",
    "print(report3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set hyperparameters\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [150, 300, 400],\n",
    "    'max_depth': [30, 40, 50, 60],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "# Create GridSearchCV instance with the parameter grid\n",
    "grid_search2 = GridSearchCV(estimator=model3, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search2.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params2 = grid_search2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest Classifier model with the best hyperparameters\n",
    "model3 = RandomForestClassifier(random_state=1, n_estimators=400, max_depth=30, min_samples_split=5)\n",
    "\n",
    "# Train the classifier on the entire training data\n",
    "model3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data once again\n",
    "y_pred4 = model3.predict(X_test)\n",
    "\n",
    "accuracy4 = accuracy_score(y_test, y_pred4)\n",
    "print(f'Accuracy: {accuracy4}')\n",
    "\n",
    "report4 = classification_report(y_test, y_pred4)\n",
    "print(report4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
