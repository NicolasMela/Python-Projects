{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Bank Term Deposit Subscriptions in a Marketing Campaign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using Bank Marketing data from UC Irvine's Machine Learning Repository. This data is related to the marketing campaigns of a Portugese banking institution. These marketing campaigns were based on calls to clients to determine if they would be subscribing to a bank term deposit.\n",
    "\n",
    "This project focuses on leveraging machine learning techniques to predict whether clients will subscribe to a term deposit as part of a direct marketing campaign. The primary goal is to develop the most accurate predictive model that can help the banking institution target its marketing efforts more effectively.\n",
    "\n",
    "The structure of this project is as follows:\n",
    "- First import and view the data\n",
    "- Focus on preprocessing & cleaning the dataset for our ML model\n",
    "- Exploratory analysis to better understand data correlation\n",
    "- Build base ML model to predict if a client would subscribe to a term deposit or not.\n",
    "- Hyperparameters of base model are fine-tuned using grid search\n",
    "- Final model is trained and its metrics are evaluated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data From UC Irvine Machine Learning Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data From UCI Machine Learning Repository\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "  \n",
    "# fetch dataset \n",
    "bank_marketing = fetch_ucirepo(id=222) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = bank_marketing.data.features \n",
    "y = bank_marketing.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(bank_marketing.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(bank_marketing.variables) \n",
    "\n",
    "pd.set_option('display.max_column', None) # Set dataframe to show max columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect predictor variable dataset\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect target variable\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View summary statistics\n",
    "print(X.describe())\n",
    "print(y.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View df info\n",
    "print(X.info)\n",
    "print(y.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View data types\n",
    "print(X.dtypes)\n",
    "print(y.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the missing values in the dataset\n",
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the missing values in target variable\n",
    "y.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the project, we first handle the missing values we discovered from the previous step in the project. Since there are only missing values in our categorical variables, I decide to fill those rows with the most frequent occurring values in their respective column. However, our 'poutcome' column has over 75% of the column with missing values, so we decide to let one-hard encoding in the next step handle those values. In other instances, I would like to drop this column, but as we see later on in the project, the 'poutcome' column has a strong correlation to the target variable, so we decide to keep it.\n",
    "\n",
    "After handling the missing values in the 'job', 'education', and 'contact' column, we focus on converting the categorical variables into numeric values with one-hard encoding using the get_dummies() method from pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null values with most frequent value\n",
    "\n",
    "columns_replace = ['job', 'education', 'contact']\n",
    "\n",
    "for col in columns_replace:\n",
    "    most_frequent_value = X[col].mode()[0]\n",
    "    X[col].fillna(most_frequent_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the missing values have been replaced\n",
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now convert categorical variables to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the categorical features to numeric ones using get_dummies() method from pandas\n",
    "X_dummies = pd.get_dummies(X) # This will give each category in each categorical column it's own separate column, with boolean True False in it's respective rows\n",
    "\n",
    "X_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't want to do the same with the target variable, since we just want one column in it's df. So we map the 'yes' and 'no' values to True/False\n",
    "\n",
    "# Changing y df from \"yes/no\" to True/False\n",
    "mapping = {'yes' : True, 'no': False}\n",
    "\n",
    "# Apply mapping to column\n",
    "y['y'] = y['y'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last thing we do now is convert the boolean values (True/False) to binary (0/1) values\n",
    "\n",
    "X_dummies = X_dummies.astype(int)\n",
    "\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check work\n",
    "print(X_dummies.dtypes)\n",
    "\n",
    "print(y.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Statistical Correlation between Predictor Variables (X) and Target Variable (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of the project, we want to view the correlation between the predictor variables and target variable. We do this to see if there are any variables we can remove for our model. However, we don't decide to remove any after this analysis since there is no single variable that has a strong correlation with the target variable, we we choose to keep them all.\n",
    "\n",
    "I also want to note that with this analysis, we see that the 'poutcome' column had the second highest correlation to the predictor variable compared to the rest, which is why we never dropped the column earlier in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at correlation with heatmap\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.concat([X_dummies, y], axis = 1) # combining predictor variables df (X) with target variable df (y)\n",
    "\n",
    "sns.heatmap(df.corr(), cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View correlation \n",
    "corr_matrix = df.corr()\n",
    "\n",
    "corr_target = corr_matrix.iloc[:-1, -1]\n",
    "\n",
    "sorted_corr = corr_target.abs().sort_values(ascending=False)\n",
    "\n",
    "print(sorted_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split data into training and testing sets (80% for training, 20% for testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, test_size=0.2, random_state=1) \n",
    "\n",
    "# 'test_size' determines the proportion of the dataset used for the training and testing data\n",
    "# 'random_state' sets the seed for reproducability "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Logist Regression Model\n",
    "regressionmodel = LogisticRegression(random_state=10)\n",
    "\n",
    "# Train model on training data\n",
    "regressionmodel.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_regression = regressionmodel.predict(X_test)\n",
    "\n",
    "# Evaluate models performance\n",
    "accuracy_regression = accuracy_score(y_test, y_pred_regression)\n",
    "print(f'Accuracy : {accuracy_regression}')\n",
    "\n",
    "# Generate a classification report\n",
    "print(classification_report(y_test, y_pred_regression))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest Classifier instance\n",
    "model_forest = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Train the classifier on training data\n",
    "model_forest.fit(X_train, y_train)\n",
    "\n",
    "# Use model to predict on test data\n",
    "y_pred_forest = model_forest.predict(X_test)\n",
    "\n",
    "# Evaluate accuracey\n",
    "accuracy_forest = accuracy_score(y_test, y_pred_forest)\n",
    "print(f'Accuracy: {accuracy_forest}')\n",
    "\n",
    "# Generate a classification report\n",
    "print(classification_report(y_test, y_pred_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gradient Boosting Classifier model\n",
    "model_gradient = GradientBoostingClassifier(random_state=1)\n",
    "\n",
    "# Train the model on training data\n",
    "model_gradient.fit(X_train, y_train)\n",
    "\n",
    "# Use model to predict on test data\n",
    "y_pred_gradient = model_gradient.predict(X_test)\n",
    "\n",
    "# Evaluate model accuracy\n",
    "accuracy_gradient = accuracy_score(y_test, y_pred_gradient)\n",
    "print(f'Accuracy: {accuracy_gradient}')\n",
    "\n",
    "# Generate a classification report\n",
    "print(classification_report(y_test, y_pred_gradient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [350, 500, 700],\n",
    "    'max_depth': [30, 40, 50, 60],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "# Create GridSearchCV instance with the parameter grid\n",
    "grid_search = GridSearchCV(estimator=model_forest, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View hyperparameters\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest Classifier model with the best hyperparameters\n",
    "model_tuned = RandomForestClassifier(random_state=1, n_estimators=350, max_depth=50, min_samples_split=5)\n",
    "\n",
    "# Train the classifier on the entire training data\n",
    "model_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data once again\n",
    "y_pred_tuned = model_tuned.predict(X_test)\n",
    "\n",
    "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "print(f'Accuracy: {accuracy_tuned}')\n",
    "\n",
    "report = classification_report(y_test, y_pred_tuned)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case of the new model, the accuracy is nearly identical to the accuracy of the initial model, indicating that the hyperparameters tuned did not have a significant impact on the model's performance for this specific dataset. \n",
    "The next possible steps to take this project even further would be to try different model algorithms, such as Neural Networks, revisit hyperparameter tuning, gather \n",
    "more data, or revisit your feature selection. This is why domain knowledge in data analysis is so important, since you can guide your feature selection based on your industry knowledge. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
